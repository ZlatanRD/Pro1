{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-mNOzBUm1BY"
      },
      "source": [
        "# Imports & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vZpBxSYMmzrG"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!wget https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n",
        "!unzip /content/nature_12K.zip\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "DvB6NNxsnJyi"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "from glob import glob\n",
        "import time\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "from torch.optim import Adam "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oQ_qcF9nxWy"
      },
      "source": [
        "# Dataloader\n",
        "\n",
        "- Dataset Class for Setting up the data loading process\n",
        "- Sections to fill in this script: `_init_transform()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "0xJnjBM-ntqN"
      },
      "outputs": [],
      "source": [
        "class inaturalist(Dataset):\n",
        "    def __init__(self, root_dir, mode = 'train', transform = True):\n",
        "        self.data_dir = root_dir\n",
        "        self.mode = mode\n",
        "        self.transforms = transform      \n",
        "        self._init_dataset()\n",
        "        if transform:\n",
        "            self._init_transform()\n",
        "\n",
        "    def _init_dataset(self):\n",
        "        self.files = []\n",
        "        self.labels = []\n",
        "        dirs = sorted(os.listdir(os.path.join(self.data_dir, 'train')))\n",
        "        if self.mode == 'train': \n",
        "            for dir in range(len(dirs)):\n",
        "                files = sorted(glob(os.path.join(self.data_dir, 'train', dirs[dir], '*.jpg')))\n",
        "                self.labels += [dir]*len(files)            \n",
        "                self.files += files\n",
        "        elif self.mode == 'val':\n",
        "            for dir in range(len(dirs)):\n",
        "                files = sorted(glob(os.path.join(self.data_dir, 'val', dirs[dir], '*.jpg')))\n",
        "                self.labels += [dir]*len(files)            \n",
        "                self.files += files\n",
        "        else:\n",
        "            print(\"No Such Dataset Mode\")\n",
        "            return None\n",
        "    \n",
        "    def _init_transform(self):\n",
        "        self.transform = transforms.Compose([\n",
        "             transforms.Resize((256,256)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(30), \n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5),(0.5))\n",
        "            #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "       #     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
        "            # Useful link for this part: https://pytorch.org/vision/stable/transforms.html\n",
        "            #----------------YOUR CODE HERE---------------------#\n",
        "        ])\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        img = Image.open(self.files[index]).convert('RGB')\n",
        "        label = self.labels[index]\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        label = torch.tensor(label, dtype = torch.long)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJccgV5Knzi6"
      },
      "source": [
        "# Model\n",
        "\n",
        "- Class to define the model which we will use for training\n",
        "- Stuff to fill in: The Architecture of your model, the `forward` function to define the forward pass\n",
        "\n",
        "NOTE!: You are NOT allowed to use pretrained models for this task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "XBCH7l47nyo6"
      },
      "outputs": [],
      "source": [
        "# VGG_19 = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']\n",
        "\n",
        "# 2 convolutional layers with max pooling and relu activation\n",
        "# then 3 linear Deep layers\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "          super(Classifier, self).__init__()\n",
        "          self.conv1 = nn.Conv2d(in_channels=3,\n",
        "                               out_channels=6,\n",
        "                               kernel_size=5)\n",
        "\n",
        "          self.conv2 = nn.Conv2d(in_channels=6,\n",
        "                               out_channels=16,\n",
        "                               kernel_size=5)\n",
        "\n",
        "          self.fc_1 = nn.Linear(16 * 61 * 61, 120)\n",
        "          self.fc_2 = nn.Linear(120, 84)\n",
        "          self.fc_3 = nn.Linear(84, n_classes)\n",
        "\n",
        "\n",
        "        # Useful Link: https://pytorch.org/docs/stable/nn.html\n",
        "        #------------ENTER YOUR MODEL HERE----------------#        \n",
        "\n",
        "    def forward(self, x):\n",
        "        #---------Assuming x to be the input to the model, define the forward pass-----------#\n",
        "        #(3, 256, 256) ---> input\n",
        "        x = self.conv1(x) \n",
        "        #(6, 252, 252) ---> output\n",
        "        x = F.max_pool2d(x, kernel_size=2)\n",
        "        #(6, 126, 126)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        #(16, 122, 122)\n",
        "        x = F.max_pool2d(x, kernel_size=2)\n",
        "        #(16, 61, 61)\n",
        "        x = F.relu(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        h = x\n",
        "        x = self.fc_1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc_2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc_3(x)\n",
        "        return x, h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i3bFLsdoF1_"
      },
      "source": [
        "# Training\n",
        "\n",
        "- Sections to Fill: Define `loss` function, `optimizer` and model, `train` and `eval` functions and the training loop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSnVvW2XoUtS"
      },
      "source": [
        "## Hyperparameters\n",
        "\n",
        "Feel free to change these hyperparams based on your machine's capactiy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "VOZBwxHUn1jl"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "epochs = 5\n",
        "learning_rate = 0.001\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZqeVDE4oZ0H"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dmsg0xP8oYTR",
        "outputId": "28502c87-6a4c-4034-9eff-d1b90e677fee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 7,158,751 trainable parameters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "trainset = inaturalist(root_dir='inaturalist_12K', mode='train')\n",
        "valset = inaturalist(root_dir='inaturalist_12K', mode = 'val')\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "valloader = DataLoader(valset, batch_size=1, shuffle=False, num_workers=4)\n",
        "\n",
        "OUTPUT_DIM = 15\n",
        "model = Classifier(OUTPUT_DIM)\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBhjYABpobqY"
      },
      "source": [
        "## Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "c8LY3Yiloe4M"
      },
      "outputs": [],
      "source": [
        "# USEFUL LINK: https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "#---Define the loss function to use, model object and the optimizer for training---#\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = Adam(model.parameters(), learning_rate)\n",
        "loss_fun = F.cross_entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9bEWwU-ohzG"
      },
      "source": [
        "## Checkpoints\n",
        "\n",
        "To save your model weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "6t5vtHaLofac"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = 'checkpoints'\n",
        "if not os.path.isdir(checkpoint_dir):\n",
        "    os.makedirs(checkpoint_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTLTwpfmopqu"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "cM9OFbjjojax"
      },
      "outputs": [],
      "source": [
        "def get_model_summary(model, input_tensor_shape):\n",
        "    summary(model, input_tensor_shape)\n",
        "\n",
        "def accuracy(y_pred, y):\n",
        "    _, predicted = torch.max(y_pred.data, 1)\n",
        "    total = y.size(0)\n",
        "    correct = (predicted == y).sum().item()\n",
        "    return correct/total\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCr-_BHxosFO"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "MaSzNltYorsv"
      },
      "outputs": [],
      "source": [
        "#def train(model, dataset, optimizer, criterion, device):\n",
        "    #------YOUR CODE HERE-----#\n",
        "\n",
        "\n",
        "def train(model, epochs, trainloader):\n",
        "    model.train()\n",
        "    total_num = len(trainloader.dataset)\n",
        "    train_loss = 0\n",
        "    correct_num = 0\n",
        "\n",
        "    for image, label in trainloader:\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "        # Convert the tag from int32 type to long type, otherwise the calculation loss will report an error\n",
        "        label = label.to(torch.long)\n",
        "\n",
        "        output,_ = model(image)\n",
        "        loss = loss_fun(output, label)\n",
        "        train_loss += loss.item() * label.size(0)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        predict = torch.argmax(output, dim=-1)\n",
        "        correct_num += label.eq(predict).sum()\n",
        "\n",
        "    train_loss = train_loss / total_num\n",
        "    train_acc = correct_num / total_num\n",
        "    print('epoch: {} --> train_loss: {:.6f} - train_acc: {:.6f} - '.format(\n",
        "        epoch, train_loss, train_acc), end='')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OadZ2Iwmouui"
      },
      "source": [
        "## Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "8NKlJQpIouM5"
      },
      "outputs": [],
      "source": [
        "#def eval(model, dataset, criterion, device):\n",
        "\n",
        "    #------YOUR CODE HERE-----#\n",
        "\n",
        "def evaluate(model, eval_ds, mode='val'):\n",
        "    model.eval()\n",
        "\n",
        "    total_num = len(eval_ds.dataset)\n",
        "    eval_loss = 0\n",
        "    correct_num = 0\n",
        "\n",
        "    for image, label in eval_ds:\n",
        "            image = image.to(device)\n",
        "            label = label.to(device)\n",
        "            label = label.to(torch.long)\n",
        "            \n",
        "            output,_ = model(image)\n",
        "        \n",
        "            loss = loss_fun(output, label)\n",
        "            eval_loss += loss.item() * label.size(0)\n",
        "\n",
        "            predict = torch.argmax(output, dim=-1)\n",
        "            correct_num += label.eq(predict).sum()\n",
        "        \n",
        "            eval_loss = eval_loss / total_num\n",
        "            eval_acc = correct_num / total_num\n",
        "    \n",
        "    print('{}_loss: {:.6f} - {}_acc: {:.6f}'.format(\n",
        "        mode, eval_loss, mode, eval_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1AIrmEeozK4"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfFkPREqov9j",
        "outputId": "a2fb575b-3906-4080-bb2e-c669ae9aee9c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0 --> train_loss: 2.204563 - train_acc: 0.206721 - val_loss: 0.001023 - val_acc: 0.168000\n",
            "epoch: 1 --> train_loss: 2.064819 - train_acc: 0.268527 - val_loss: 0.000665 - val_acc: 0.200000\n",
            "epoch: 2 --> train_loss: 2.002788 - train_acc: 0.292629 - val_loss: 0.001123 - val_acc: 0.168000\n",
            "epoch: 3 --> train_loss: 1.950952 - train_acc: 0.314831 - val_loss: 0.000696 - val_acc: 0.245000\n",
            "epoch: 4 --> train_loss: 1.913288 - train_acc: 0.328533 - val_loss: 0.000896 - val_acc: 0.216500\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(5):\n",
        "    train(model, epoch, trainloader)\n",
        "    evaluate(model, valloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJEmmbNqo13e",
        "outputId": "13fb3223-6beb-4450-b209-6da5afb1eac8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_loss: 0.002529 - test_acc: 0.346735\n"
          ]
        }
      ],
      "source": [
        "evaluate(model, trainloader, mode='test')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "2. Summer_School_Task_3_<Rutvik>.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
